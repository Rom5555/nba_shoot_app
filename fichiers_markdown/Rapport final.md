# ğŸ“‘ Rapport final



### âœ… Conclusion tirÃ©es

Lâ€™analyse de 4 saisons de tirs NBA extraites via nba_api a montrÃ© que les performances au tir sont fortement contextuelles : la distance au panier (SHOT_DISTANCE), les cumuls rÃ©cents (LAST_5_PCT / LAST_5D_PCT), lâ€™angle du tir (ANGLE_TO_HOOP) et le contexte de score (SCOREMARGIN) sont des prÃ©dicteurs robustes. Les modÃ¨les classiques (RandomForest, XGBoost) obtiennent des performances stables autour de 0.62â€“0.66 dâ€™accuracy et 0.64â€“0.66 dâ€™AUC ROC selon les itÃ©rations documentÃ©es. Le deep learning (MLP wide&deep, TabNet) nâ€™a pas dÃ©passÃ© significativement ces scores sur le jeu disponible, indiquant que la richesse des features et la variabilitÃ© individuelle des joueurs pÃ¨sent plus que la complexitÃ© du modÃ¨le.

---

### âš ï¸ DifficultÃ©s rencontrÃ©es lors du projet

Le principal verrou scientifique a Ã©tÃ© la difficultÃ© Ã  obtenir de donnÃ©es brut concernant le tracking des joueurs en temps reel sur le terrain, ce qui aurait permis de connaitre la proximitÃ© du dÃ©fenseur ou d'un coequipier. Le basket_ball Ã©tant un sport d'Ã©quipe et d'aversitÃ© le poids de l'aide apportÃ©s par les coÃ©quipiers n'a pas pu Ãªtre capturÃ© de maniÃ¨re significative, de mÃªme l'impact des defenseur n'a pu Ãªtre obtenu que par approximation, en reconstruisant des features Ã  partir de donnÃ©es dÃ©jÃ  aggrÃ©gÃ©es Ã  l'echelle d'un match et non action par action comme pour le dataset de base contenant les shoots. Par defaut nous n'avons pas pu obenir au moins une variable shoot contestÃ©/shoot libre. Ces donnÃ©es sont proprietÃ©s des Ã©quipes de NBA et ne sont pas accessible librement. La reconstruction de ces variables par approximation Ã  considerablement diluÃ© l'impact de ces features. 

#### â³ PrÃ©visionnel : tÃ¢ches qui ont pris plus de temps que prÃ©vu

- Recuperation des datas pertinentes Ã  partirs d'un multitude de dataframe servi par les endpoints de NBA_API. La plupart des donnÃ©es Ã©tant dÃ©jÃ  aggregÃ© par match ou par saison, ce qui complique et limite leur utilisation dans le cadre de notre sujet qui se situe Ã  l'echelle action par action.
- Feature engenneering, reconstruction de variable utilisable pour notre modele Ã  partir de ces donnÃ©es aggrÃ©gÃ©es.
- Conception et vÃ©rification des cumuls causaux (shift/ordering) : plusieurs itÃ©rations pour garantir absence de fuite temporelle.
- Tuning de modÃ¨les (GridSearch / Randomized / Optuna) sur validation temporelle : longue consommation CPU et itÃ©rations rÃ©pÃ©tÃ©es.
- IntÃ©gration et extraction de features avancÃ©es (ANGLE_TO_HOOP, dÃ©fensives agrÃ©gÃ©es) : complexitÃ© mathÃ©matique et vÃ©rifications gÃ©omÃ©triques.

#### ğŸ“Š Jeux de donnÃ©es : acquisition, volumÃ©trie, traitement, agrÃ©gation

- Acquisition : rÃ©cupÃ©ration via nba_api sur 4 saisons â€” reproductible mais lente (API rate limits et nettoyage nÃ©cessaire).
- VolumÃ©trie : ~37k tirs documentÃ©s dans le premier rapport, plusieurs centaines de milliers dâ€™Ã©vÃ©nements selon granularitÃ© PlayByPlay ; taille suffisante pour ML classique mais limitÃ©e pour DL profond.
- Traitement : nettoyage, imputation (ex SCOREMARGIN), calcul de cumuls/rolling, agrÃ©gation par joueur/zone, variables temporelles agregees pour caturer la fatigue, reconstructions de variables pour capturer l'impact de la dÃ©fense Ã  partir de donnÃ©es par match.

#### ğŸ§‘â€ğŸ’» CompÃ©tences techniques / thÃ©oriques

- Acquisition rapide de compÃ©tences pratiques en XGBoost, TabNet et Keras; montage dâ€™un pipeline ColumnTransformer/OneHot/Scaler.
- DifficultÃ©s initiales : implÃ©mentation correcte des validations temporelles (TimeSeriesSplit vs split par date), gestion des features hiÃ©rarchiques (effet joueur), et interprÃ©tabilitÃ© (mise en place SHAP).

#### ğŸ¯Pertinence : de lâ€™approche, du modÃ¨le, des donnÃ©es

- Approche : pertinente (features contextuelles + rolling), mais perfectible : rÃ©gularisation bayÃ©sienne souhaitable pour cumuls sur petits effectifs et modÃ¨les hiÃ©rarchiques (mixed-effects) pour capturer lâ€™effet joueur.
- ModÃ¨les : XGBoost offre le meilleur compromis performance/temps. DL intÃ©ressant mais limitÃ© par volume et signal disponible.
- DonnÃ©es : nÃ©cessitÃ© dâ€™enrichir par variables dÃ©fensives par possession, tracking player-level (if available), et contexte dâ€™Ã©quipe adversaire.

#### ğŸ–¥ï¸ IT : puissance de stockage, puissance computationnelle

- EntraÃ®nements et Grid/Random Search lourds en CPU; Optuna utile mais demande ressources.
- Deep learning (Keras/TabNet) demande GPU pour accÃ©lÃ©rer; absence de GPU rend lâ€™itÃ©ration plus lente.
- Stockage: jeux csv/npz et objets picklÃ©s suffisamment petits, mais snapshots dâ€™historique et versions de preprocessors Ã  sauvegarder pour reproductibilitÃ©.

#### ğŸ“Œ Autres

- Visualisations interactives (Streamlit) faciles Ã  prototyper mais la configuration des exports (pickle/keras save) nÃ©cessite des conventions robustes pour dÃ©ploiement.

---

### ğŸ“ˆ Bilan

#### ğŸŒŸ Contribution principale

- Conception et implÃ©mentation du pipeline end-to-end : ingestion via nba_api, nettoyage, feature engineering (cumuls par zone/type, rolling windows, ANGLE_TO_HOOP, DAYS_SINCE_LAST_GAME), pipelines sklearn (ColumnTransformer), Ã©valuation et prototypes modÃ¨les (RandomForest, XGBoost, Keras wide&deep, TabNet).
- Mise en place dâ€™une application Streamlit/visualisation (notebook / app scaffolding) pour inspection des mÃ©triques, confusion matrices et importance de features.

#### ğŸ”„ Evolution des modÃ¨les

- Oui. ItÃ©rations documentÃ©es :
  - Passage dâ€™un RandomForest brut (baseline) Ã  GridSearchCV optimisÃ© (meilleure profondeur et n_estimators) -> gain accuracy ~0.03.
  - Introduction XGBoost optimisÃ© (learning_rate, max_depth, subsample) -> meilleure CV score.
  - Ajout dâ€™un modÃ¨le wide&deep Keras et TabNet pour tester capacitÃ©s non linÃ©aires profondes ; gains marginaux nuls au regard du travail dâ€™ingÃ©nierie des features.
  - Ajout de transformations standardisÃ©es et dâ€™un encodage dense pour compatibilitÃ© Keras.

#### ğŸ“Š RÃ©sultats obtenus

- RandomForest (non optimisÃ©) : accuracy â‰ˆ 0.60, AUC â‰ˆ 0.64 (ex Rapport_2).
- RandomForest (GridSearch) : accuracy â‰ˆ 0.63, amÃ©lioration notable sur recall pour Â« Miss Â».
- XGBoost (GridSearch) : accuracy â‰ˆ 0.65, best CV score â‰ˆ 0.657 ; meilleure sÃ©paration et AUC plus Ã©levÃ©e.
- Keras / TabNet : accuracy â‰ˆ 0.62â€“0.63, AUC â‰ˆ 0.65 ; stabilitÃ© mais pas de dÃ©passement significatif.
  Benchmark attendu (baseline raisonnable) : prÃ©diction par zone/type (taux historique) â€” nos modÃ¨les amÃ©liorent ce baseline en captant interactions contextuelles, mais la marge dâ€™amÃ©lioration reste modeste.

#### ğŸ¯ Atteintes des objectifs

- Explorer et visualiser les donnÃ©es : Atteint â€” heatmaps, distributions, confusion matrices, feature importances et SHAP.
- Construire variables cumulÃ©es / temporelles : Atteint â€” LAST_5*, LAST_5D*, TOTAL_CUM_*, ANGLE_TO_HOOP, DAYS_SINCE_LAST_GAME.
- Identifier patterns de jeu : Partiellement atteint â€” zones et types prÃ©fÃ©rÃ©s identifiÃ©s globalement; personnalisation par joueur limitÃ©e par variance et petits effectifs.
- PrÃ©parer dataset final pour classification supervisÃ©e : Atteint â€” pipeline preprocess prÃªt pour entraÃ®nement reproductible.
- DÃ©velopper modÃ¨le prÃ©dictif : Atteint â€” plusieurs modÃ¨les entraÃ®nÃ©s et comparÃ©s ; performances solides mais perfectibles.

#### ğŸ€ Process mÃ©tier oÃ¹ le modÃ¨le peut sâ€™inscrire

- Aide Ã  la dÃ©cision tactique : Ã©valuer probabilitÃ© de rÃ©ussite par zone/joueur en situation de jeu (scouting, prÃ©paration dâ€™adversaire).
- Analyse de performance joueur : dÃ©tection de hot/cold streaks via LAST_5* et alertes.
- Valorisation/choix de recrutement : probabilitÃ© ajustÃ©e par contexte pouvant servir en complÃ©ment dâ€™Ã©valuation de scouting.

---

### ğŸš€ Suite du projet

#### ğŸ“Œ Pistes dâ€™amÃ©lioration

1. Enrichir les features dÃ©fensives par possession (opponent zone defense metrics, defender distance from shooter) si tracking data disponible.
2. Passer XGBoost/LightGBM avec feature interactions automatiques et tuning bayÃ©sien systÃ©matique (Optuna) sur CV temporel.
3. Modelisation hierarchique pour integrer les variables Ã  differentes echelles (mixed effects) 
4. Calibration fine des probabilitÃ©s (isotonic/platt) pour applicabilitÃ© opÃ©rationnelle.
5. Data augmentation temporelle : inclure sequences via RNN/transformer sur shots rÃ©cents (si volume de sÃ©quences joueur suffisant).
6. DÃ©ploiement GPU pour accÃ©lÃ©rer lâ€™itÃ©ration deep learning et lâ€™hyperparam tuning.

#### ğŸ”¬ Contribution scientifique

- Validation empirique que, dans le contexte des tirs NBA, lâ€™ingÃ©nierie des features (cumuls causaux, angle) est plus critique que la complexitÃ© du modÃ¨le.
- Mise en Ã©vidence de la nÃ©cessitÃ© de mÃ©thodes hiÃ©rarchiques et de rÃ©gularisation pour traiter la variance interâ€‘joueurs.
- Documentation reproductible du pipeline (preprocessing, validation temporelle) applicable Ã  dâ€™autres Ã©tudes dâ€™Ã©vÃ©nements sportifs ponctuels.

### ğŸ“… Annexes

#### ğŸ“† Diagramme de Gantt (texte rÃ©sumÃ©)

- Semaine 1â€“2 : collecte des donnÃ©es via nba_api, exploration initiale, dÃ©finition des variables clÃ©s.
- Semaine 2â€“3 : implÃ©mentation du prÃ©processing, calcul des cumuls et features temporelles, vÃ©rifications causales, baselines (RandomForest,XGBOOST), visualisations et premiÃ¨res Ã©valuations.
- Semaine 3â€“4 : tuning GridSearch/Randomized/XGBoost, validation temporelle.
- Semaine 4-5 : prototypes deep learning (Keras wide&deep, TabNet), Ã©valuation et comparaison.
- Semaine 5-6 : intÃ©gration Streamlit, calibration et prÃ©paration du rapport final.

#### ğŸ“‚ Description des fichiers de code fournis

- app.py (Streamlit) : interface pour  gerer les pages multiples.
- data_page.py: affichage du dataset
- vizualisation.py et vizualisation_page.py: construction des graphes de dataviz Ã  partir de certaines variables du dataset
- models.py et models_page.py (version ML):
  - DÃ©finit les listes de colonnes par type (numerical_continuous, numerical_counts, categorical, boolean, target).
  - get_preprocessor(X) : construit ColumnTransformer (StandardScaler/OneHotEncoder/passthrough).
  - create_pipeline(model, X) : Pipeline(preprocessor, classifier).
  - train_and_eval(...) : entraÃ®ne pipeline, retourne classification_report, AUC et figure matrice de confusion.
  - grid_search_pipeline(...) : GridSearchCV avec TimeSeriesSplit, extraction des feature importances et figure top-20.
  - randomized_search_pipeline(...) et optuna_tune(...) : recherche dâ€™hyperparamÃ¨tres via RandomizedSearchCV et Optuna.
  - evaluate_model(...) : utilisation orientÃ©e Streamlit pour afficher rapports, matrice de confusion et importances (si fournies).
  - Points dâ€™attention : gestion des get_feature_names_out() avec fallback, compatibilitÃ© avec diffÃ©rents estimateurs.
  - Gere les sauvegardes/chargements des modeles 

- deep_learning.py et deep_learning_page.py (partie Keras / TabNet)
  
  - preprocess_data(X_train, X_test, ...) : ColumnTransformer pour features continues, catÃ©gorielles (oneâ€‘hot dense) et boolÃ©ennes ; renvoie arrays float32 et preprocessor.
  - build_wide_deep(input_dim) : architecture Keras wide & deep, batchnorm/dropout, compile avec Adam.
  - build_tabnet() : constructeur TabNetClassifier (paramÃ¨tres proposÃ©s).
  - train_and_eval(...) : entraine Keras ou TabNet selon model_type, gÃ¨re early stopping, retourne model, report, auc, figures et history.
  - eval_deep(...) : Ã©value modÃ¨le deep, construit matrice de confusion et trace lâ€™historique si disponible; compatible Keras et TabNet.
  - prepare_save_object(...) : prÃ©pare dict pour sauvegarde (modÃ¨le, preprocessor, history) avec avertissement sur pickling.
  - Gere les sauvegardes/chargement des modeles

- prediction.py et prediction_page.py: petit jeu de prediction en live avec XGBOOST simple, reglages des 3 features plus importantes par l'utilisateur.

- requirements.txt : versions exactes de packages (scikit-learn, xgboost, tensorflow, pytorch/tabnet, shap, optuna, joblib).
- notebook_repro.ipynb : exÃ©cution pas-Ã -pas du pipeline sur un sous-ensemble Ã©chantillon.

---
